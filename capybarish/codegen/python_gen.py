"""
Python Code Generator for Capybarish schemas.

Generates Python dataclasses with serialization methods from .cpy schema files.

Copyright 2025 Chen Yu <chenyu@u.northwestern.edu>

Licensed under the Apache License, Version 2.0.
"""

from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

from .parser import FieldDef, FieldType, MessageDef, SchemaDef, SchemaParser, TYPE_INFO


class PythonGenerator:
    """Generates Python code from Capybarish schema definitions."""
    
    # Python type annotations for each field type
    PYTHON_TYPES = {
        FieldType.INT8: "int",
        FieldType.INT16: "int",
        FieldType.INT32: "int",
        FieldType.INT64: "int",
        FieldType.UINT8: "int",
        FieldType.UINT16: "int",
        FieldType.UINT32: "int",
        FieldType.UINT64: "int",
        FieldType.FLOAT32: "float",
        FieldType.FLOAT64: "float",
        FieldType.FLOAT: "float",
        FieldType.DOUBLE: "float",
        FieldType.INT: "int",
        FieldType.BOOL: "bool",
        FieldType.BYTE: "int",
        FieldType.CHAR: "str",
    }
    
    # Default values for each type
    DEFAULT_VALUES = {
        FieldType.INT8: "0",
        FieldType.INT16: "0",
        FieldType.INT32: "0",
        FieldType.INT64: "0",
        FieldType.UINT8: "0",
        FieldType.UINT16: "0",
        FieldType.UINT32: "0",
        FieldType.UINT64: "0",
        FieldType.FLOAT32: "0.0",
        FieldType.FLOAT64: "0.0",
        FieldType.FLOAT: "0.0",
        FieldType.DOUBLE: "0.0",
        FieldType.INT: "0",
        FieldType.BOOL: "False",
        FieldType.BYTE: "0",
        FieldType.CHAR: "''",
    }
    
    def __init__(self, schema: SchemaDef):
        self.schema = schema
        self.parser = SchemaParser()
    
    def _has_any_nested_types(self) -> bool:
        """Check if any message in the schema has nested types."""
        for msg in self.schema.messages.values():
            if any(f.is_nested for f in msg.fields):
                return True
        return False
    
    def generate(self) -> str:
        """Generate complete Python module."""
        lines = []
        
        # Header
        lines.extend(self._generate_header())
        lines.append("")
        
        # Imports
        lines.extend(self._generate_imports())
        lines.append("")
        lines.append("")
        
        # Add helper functions if there are nested types
        if self._has_any_nested_types():
            lines.extend(self._generate_module_helpers())
            lines.append("")
            lines.append("")
        
        # Get messages in dependency order
        msg_order = self.parser.get_dependency_order(self.schema)
        
        # Generate message classes
        for msg_name in msg_order:
            msg = self.schema.messages[msg_name]
            lines.extend(self._generate_message_class(msg))
            lines.append("")
            lines.append("")
        
        # Generate registry
        lines.extend(self._generate_registry(msg_order))
        
        return "\n".join(lines)
    
    def _generate_header(self) -> List[str]:
        """Generate file header."""
        package_name = self.schema.package or "messages"
        source = self.schema.source_file or "schema"
        
        return [
            '"""',
            f"Auto-generated message definitions for {package_name}.",
            "",
            f"Generated from: {source}",
            f"Generated at: {datetime.now().isoformat()}",
            "",
            "DO NOT EDIT - This file is auto-generated by capybarish-gen.",
            '"""',
        ]
    
    def _generate_imports(self) -> List[str]:
        """Generate import statements."""
        return [
            "import struct",
            "from dataclasses import dataclass, field, fields",
            "from typing import Any, ClassVar, Dict, List, Optional, Tuple, Type, Union",
        ]
    
    def _generate_module_helpers(self) -> List[str]:
        """Generate module-level helper functions for nested types."""
        return [
            "# Helper functions for nested type serialization",
            "def _flatten_nested(obj: Any) -> List:",
            '    """Flatten a nested dataclass to a list of primitive values."""',
            "    values = []",
            "    for f in fields(obj):",
            "        val = getattr(obj, f.name)",
            "        if hasattr(val, '__dataclass_fields__'):",
            "            values.extend(_flatten_nested(val))",
            "        elif isinstance(val, list) and val and hasattr(val[0], '__dataclass_fields__'):",
            "            for item in val:",
            "                values.extend(_flatten_nested(item))",
            "        elif isinstance(val, list):",
            "            values.extend(val)",
            "        else:",
            "            values.append(val)",
            "    return values",
            "",
            "",
            "def _unflatten_nested(cls: Type, values: Tuple, start_idx: int = 0) -> Tuple[Any, int]:",
            '    """Reconstruct a nested dataclass from a flat tuple of values."""',
            "    obj = cls()",
            "    idx = start_idx",
            "    for f in fields(obj):",
            "        field_type = f.type",
            "        # Handle string type annotations",
            "        if isinstance(field_type, str):",
            "            field_type = globals().get(field_type, field_type)",
            "        # Check if it's a nested dataclass by checking default_factory",
            "        if f.default_factory is not type(None) and hasattr(f.default_factory, '__self__'):",
            "            # It's a nested type",
            "            nested_cls = f.default_factory.__self__.__class__",
            "            nested_obj, idx = _unflatten_nested(nested_cls, values, idx)",
            "            setattr(obj, f.name, nested_obj)",
            "        elif hasattr(field_type, '__dataclass_fields__'):",
            "            nested_obj, idx = _unflatten_nested(field_type, values, idx)",
            "            setattr(obj, f.name, nested_obj)",
            "        else:",
            "            setattr(obj, f.name, values[idx])",
            "            idx += 1",
            "    return obj, idx",
        ]
    
    def _generate_message_class(self, msg: MessageDef) -> List[str]:
        """Generate a dataclass for a message."""
        lines = []
        
        # Check if this message has nested types
        has_nested = any(f.is_nested for f in msg.fields)
        
        # Class docstring
        if msg.comment:
            lines.append(f'# {msg.comment}')
        
        lines.append("@dataclass")
        lines.append(f"class {msg.name}:")
        
        # Docstring
        lines.append(f'    """Message type: {msg.name}."""')
        lines.append("")
        
        # Calculate struct format
        struct_format = msg.get_struct_format(self.schema.messages)
        msg_size = msg.get_size(self.schema.messages)
        
        # Class variables for format info
        lines.append(f"    _FORMAT: ClassVar[str] = '{struct_format}'")
        lines.append(f"    _SIZE: ClassVar[int] = {msg_size}")
        lines.append("")
        
        # Fields
        for f in msg.fields:
            lines.extend(self._generate_field(f))
        
        lines.append("")
        
        # Methods
        lines.extend(self._generate_serialize_method(msg, has_nested))
        lines.append("")
        lines.extend(self._generate_deserialize_method(msg, has_nested))
        lines.append("")
        lines.extend(self._generate_size_method())
        
        return lines
    
    def _generate_field(self, f: FieldDef) -> List[str]:
        """Generate a field definition."""
        lines = []
        
        if f.is_nested:
            type_name = f.type_name
            if f.is_array:
                type_annotation = f"List[{type_name}]"
                default = f"field(default_factory=lambda: [{type_name}() for _ in range({f.array_size})])"
            else:
                type_annotation = type_name
                default = f"field(default_factory={type_name})"
        else:
            py_type = self.PYTHON_TYPES[f.field_type]
            default_val = self.DEFAULT_VALUES[f.field_type]
            
            if f.is_array:
                type_annotation = f"List[{py_type}]"
                default = f"field(default_factory=lambda: [{default_val}] * {f.array_size})"
            else:
                type_annotation = py_type
                default = default_val
        
        comment = f"  # {f.comment}" if f.comment else ""
        lines.append(f"    {f.name}: {type_annotation} = {default}{comment}")
        
        return lines
    
    def _generate_serialize_method(self, msg: MessageDef, has_nested: bool = False) -> List[str]:
        """Generate the serialize method."""
        lines = [
            "    def serialize(self) -> bytes:",
            '        """Serialize message to bytes."""',
        ]
        
        if has_nested:
            # Use the module-level flatten helper
            lines.append("        values = _flatten_nested(self)")
            lines.append("        return struct.pack(self._FORMAT, *values)")
        else:
            # Simple case - no nested types
            field_values = []
            for f in msg.fields:
                if f.is_array:
                    field_values.append(f"*self.{f.name}")
                else:
                    field_values.append(f"self.{f.name}")
            values_str = ", ".join(field_values)
            lines.append(f"        return struct.pack(self._FORMAT, {values_str})")
        
        return lines
    
    def _generate_deserialize_method(self, msg: MessageDef, has_nested: bool = False) -> List[str]:
        """Generate the deserialize class method."""
        lines = [
            "    @classmethod",
            f"    def deserialize(cls, data: bytes) -> '{msg.name}':",
            '        """Deserialize message from bytes."""',
            "        if len(data) < cls._SIZE:",
            f'            raise ValueError(f"Buffer too small: {{len(data)}} < {{cls._SIZE}}")',
            "        values = struct.unpack(cls._FORMAT, data[:cls._SIZE])",
        ]
        
        if has_nested:
            # Use module-level unflatten helper
            lines.append(f"        obj, _ = _unflatten_nested(cls, values)")
        else:
            # Simple case - assign values directly
            lines.append(f"        obj = cls()")
            idx = 0
            for f in msg.fields:
                if f.is_array:
                    lines.append(f"        obj.{f.name} = list(values[{idx}:{idx + f.array_size}])")
                    idx += f.array_size
                else:
                    lines.append(f"        obj.{f.name} = values[{idx}]")
                    idx += 1
        
        lines.append("        return obj")
        
        return lines
    
    def _generate_size_method(self) -> List[str]:
        """Generate the size method."""
        return [
            "    @classmethod",
            "    def size(cls) -> int:",
            '        """Get serialized size in bytes."""',
            "        return cls._SIZE",
        ]
    
    def _count_primitive_fields(self, msg: MessageDef) -> int:
        """Count total number of primitive fields (flattened)."""
        count = 0
        for f in msg.fields:
            if f.is_nested:
                nested_msg = self.schema.messages[f.type_name]
                nested_count = self._count_primitive_fields(nested_msg)
                count += nested_count * (f.array_size or 1)
            else:
                count += f.array_size or 1
        return count
    
    def _generate_registry(self, msg_order: List[str]) -> List[str]:
        """Generate message registry."""
        lines = [
            "# Message registry for dynamic lookup",
            "MESSAGE_TYPES: Dict[str, type] = {",
        ]
        for msg_name in msg_order:
            lines.append(f'    "{msg_name}": {msg_name},')
        lines.append("}")
        lines.append("")
        lines.append("")
        lines.append("def get_message_type(name: str) -> Optional[type]:")
        lines.append('    """Get message class by name."""')
        lines.append("    return MESSAGE_TYPES.get(name)")
        
        return lines
    
    def write_file(self, output_path: str) -> None:
        """Generate and write Python code to file."""
        content = self.generate()
        path = Path(output_path)
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, "w") as f:
            f.write(content)


def generate_python(schema: SchemaDef, output_path: str) -> None:
    """Convenience function to generate Python code from schema."""
    generator = PythonGenerator(schema)
    generator.write_file(output_path)
